{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "dftrain = pd.read_csv('data/extras/train.csv', header=None)\n",
    "dftest = pd.read_csv('data/extras/test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dftrain.iloc[:, 1:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# features = ['AvgPointsPerGame', 'atHome', '7GameAvg', 'FloorAvg']\n",
    "\n",
    "X_train = scaler.fit_transform(df_train.iloc[:,:-1].values)\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "#y_train_onehot = pd.get_dummies(df_train['4GameAvg']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dftest.iloc[:, 1:]\n",
    "\n",
    "X_test = scaler.transform(df_test.iloc[:, :-1].values)\n",
    "y_test = df_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\nbuilding tree 2 of 10\nbuilding tree 3 of 10\nbuilding tree 4 of 10\nbuilding tree 5 of 10\nbuilding tree 6 of 10\nbuilding tree 7 of 10\nbuilding tree 8 of 10\nbuilding tree 9 of 10\nbuilding tree 10 of 10\n\naccuracy 0.487640449438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(random_state=0, verbose=3)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = model.predict(X_test)\n",
    "print (\"\\naccuracy\", np.sum(abs(y_prediction-y_test)<5) / float(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (445,2) (445,) ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f39d790e522b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prediction\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (445,2) (445,) "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "np.sum((y_prediction/y_test)<10)/float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ntime taken 0.6524238586425781 seconds\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=38, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "          \n",
    "          \n",
    "model.compile(optimizer='sgd', metrics=['accuracy'],loss=\"mean_squared_error\")\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=False)\n",
    "\n",
    "print ('\\ntime taken %s seconds' % str(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/445 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r416/445 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.67%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train,y_train)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99999237],\n       [ 0.9609983 ],\n       [ 0.99983823],\n       [ 0.98180032],\n       [ 0.99079728],\n       [ 0.98044753],\n       [ 0.99097919],\n       [ 0.99993837],\n       [ 0.98770881],\n       [ 0.96385992],\n       [ 0.91424108],\n       [ 0.98743457],\n       [ 0.98046517],\n       [ 0.9831987 ],\n       [ 0.98906124],\n       [ 0.99994731],\n       [ 0.99999976],\n       [ 0.96314794],\n       [ 0.94168222],\n       [ 0.98992389],\n       [ 0.92021793],\n       [ 0.98883444],\n       [ 0.98528779],\n       [ 0.99972373],\n       [ 0.99144506],\n       [ 0.99992788],\n       [ 0.97083843],\n       [ 0.98859465],\n       [ 0.98608649],\n       [ 0.99739909],\n       [ 0.98612761],\n       [ 0.99961805],\n       [ 0.98538256],\n       [ 0.99939716],\n       [ 0.95139599],\n       [ 0.9697206 ],\n       [ 0.96667743],\n       [ 0.98197007],\n       [ 0.98722851],\n       [ 0.97321653],\n       [ 0.98010892],\n       [ 0.99999845],\n       [ 0.96874362],\n       [ 0.95216531],\n       [ 0.98904514],\n       [ 0.99132079],\n       [ 0.94912446],\n       [ 0.99960631],\n       [ 0.98749369],\n       [ 0.99912232],\n       [ 0.99095494],\n       [ 0.98614568],\n       [ 0.99079728],\n       [ 1.        ],\n       [ 0.98650533],\n       [ 0.97337466],\n       [ 0.96752834],\n       [ 0.95796728],\n       [ 0.97953302],\n       [ 0.9631831 ],\n       [ 0.96477991],\n       [ 0.99996316],\n       [ 0.97454798],\n       [ 0.97309601],\n       [ 0.98984587],\n       [ 0.99913871],\n       [ 0.99556422],\n       [ 0.97209579],\n       [ 0.9906466 ],\n       [ 1.        ],\n       [ 0.9997707 ],\n       [ 0.9808349 ],\n       [ 0.97894603],\n       [ 0.91740948],\n       [ 0.97702575],\n       [ 0.94324255],\n       [ 0.98811823],\n       [ 0.99937469],\n       [ 0.98268515],\n       [ 0.92611319],\n       [ 0.98661089],\n       [ 0.99971372],\n       [ 0.99138242],\n       [ 0.97851503],\n       [ 0.99999273],\n       [ 0.98381835],\n       [ 0.95940506],\n       [ 0.99057651],\n       [ 0.99079728],\n       [ 0.98013121],\n       [ 0.99962008],\n       [ 0.99538666],\n       [ 0.98920757],\n       [ 0.99486876],\n       [ 0.98705161],\n       [ 0.99988902],\n       [ 0.97240531],\n       [ 0.9999789 ],\n       [ 0.99995005],\n       [ 0.99403375],\n       [ 0.98758405],\n       [ 0.95446861],\n       [ 0.99785209],\n       [ 0.97101349],\n       [ 0.97568941],\n       [ 0.9548105 ],\n       [ 0.93402529],\n       [ 0.97190136],\n       [ 0.98957866],\n       [ 0.99999201],\n       [ 0.99084926],\n       [ 0.98830706],\n       [ 0.98805261],\n       [ 0.9457866 ],\n       [ 0.99999976],\n       [ 0.98178101],\n       [ 1.        ],\n       [ 0.94613242],\n       [ 1.        ],\n       [ 0.99996269],\n       [ 0.99919242],\n       [ 0.99920362],\n       [ 0.98864007],\n       [ 0.98710179],\n       [ 0.975223  ],\n       [ 0.99067152],\n       [ 0.99991894],\n       [ 1.        ],\n       [ 0.97122747],\n       [ 0.99003029],\n       [ 0.98963213],\n       [ 0.98910999],\n       [ 0.96285087],\n       [ 0.95847666],\n       [ 0.99002588],\n       [ 0.9846822 ],\n       [ 0.99999952],\n       [ 0.99834955],\n       [ 0.99644071],\n       [ 0.99999928],\n       [ 0.98824036],\n       [ 0.99079728],\n       [ 0.99464476],\n       [ 0.93336701],\n       [ 0.99463427],\n       [ 0.98365533],\n       [ 0.99939454],\n       [ 0.97300637],\n       [ 0.9852497 ],\n       [ 0.98415458],\n       [ 0.99803466],\n       [ 0.98127133],\n       [ 0.97673529],\n       [ 0.99936074],\n       [ 0.90482575],\n       [ 0.99484259],\n       [ 0.99211568],\n       [ 0.96463668],\n       [ 0.96762139],\n       [ 0.99991906],\n       [ 0.95607734],\n       [ 0.9999007 ],\n       [ 0.98826319],\n       [ 0.99126351],\n       [ 0.97637522],\n       [ 0.99079728],\n       [ 0.95765299],\n       [ 0.94441462],\n       [ 0.98173714],\n       [ 0.99996579],\n       [ 0.99988341],\n       [ 0.94933295],\n       [ 0.99079728],\n       [ 0.9995271 ],\n       [ 0.90622652],\n       [ 0.96840727],\n       [ 0.9999994 ],\n       [ 0.96477568],\n       [ 0.96875203],\n       [ 0.98902494],\n       [ 0.97058284],\n       [ 0.99055582],\n       [ 0.988047  ],\n       [ 0.98194319],\n       [ 0.97215849],\n       [ 0.99999881],\n       [ 0.99879456],\n       [ 0.99974149],\n       [ 0.98224247],\n       [ 0.9879958 ],\n       [ 0.98811007],\n       [ 0.99079728],\n       [ 0.9829936 ],\n       [ 1.        ],\n       [ 0.92990088],\n       [ 0.97723299],\n       [ 0.93485779],\n       [ 0.99086326],\n       [ 0.99987197],\n       [ 0.9999634 ],\n       [ 0.99977642],\n       [ 0.99079728],\n       [ 0.95411068],\n       [ 0.99999321],\n       [ 0.99009436],\n       [ 1.        ],\n       [ 0.98434478],\n       [ 0.95135558],\n       [ 0.9288345 ],\n       [ 0.98778486],\n       [ 0.96539211],\n       [ 0.95883745],\n       [ 0.99956852],\n       [ 0.97186232],\n       [ 0.98680264],\n       [ 0.99999583],\n       [ 0.94673789],\n       [ 0.99084634],\n       [ 0.94201505],\n       [ 0.98339301],\n       [ 0.99136388],\n       [ 0.99977404],\n       [ 0.95953763],\n       [ 0.99835712],\n       [ 0.98789006],\n       [ 0.99762148],\n       [ 0.98314834],\n       [ 0.99998808],\n       [ 0.99999928],\n       [ 0.95223117],\n       [ 0.98866934],\n       [ 0.99678075],\n       [ 0.93540865],\n       [ 0.98520237],\n       [ 0.99989355],\n       [ 0.98798323],\n       [ 0.99063444],\n       [ 0.97725755],\n       [ 0.97032475],\n       [ 0.99889708],\n       [ 0.98484635],\n       [ 0.99994099],\n       [ 0.99997973],\n       [ 0.98764879],\n       [ 0.99998999],\n       [ 0.99916852],\n       [ 0.99771118],\n       [ 0.98273671],\n       [ 0.97028011],\n       [ 0.98993438],\n       [ 0.98025745],\n       [ 0.99039865],\n       [ 0.97303355],\n       [ 0.97433811],\n       [ 0.94835383],\n       [ 0.9810378 ],\n       [ 0.95619994],\n       [ 0.98572206],\n       [ 0.97302318],\n       [ 0.96997023],\n       [ 0.95752919],\n       [ 0.99999452],\n       [ 0.99981874],\n       [ 0.99037445],\n       [ 0.98886198],\n       [ 0.99999201],\n       [ 0.95689857],\n       [ 0.9999994 ],\n       [ 0.98668158],\n       [ 0.99531472],\n       [ 0.98781025],\n       [ 0.99132526],\n       [ 0.99991333],\n       [ 0.95757151],\n       [ 0.99837178],\n       [ 0.97347313],\n       [ 0.96963781],\n       [ 0.99566346],\n       [ 0.98521197],\n       [ 0.999946  ],\n       [ 0.94092989],\n       [ 0.99079728],\n       [ 0.99925369],\n       [ 0.95885408],\n       [ 0.99998128],\n       [ 0.99999988],\n       [ 0.89124429],\n       [ 0.9968574 ],\n       [ 0.98070061],\n       [ 0.99061918],\n       [ 0.99156064],\n       [ 0.97978103],\n       [ 0.97938889],\n       [ 0.99595571],\n       [ 0.94712645],\n       [ 0.99654394],\n       [ 0.97928816],\n       [ 0.99999964],\n       [ 0.99610245],\n       [ 0.99999976],\n       [ 0.99912363],\n       [ 0.98902518],\n       [ 0.98128295],\n       [ 0.97773176],\n       [ 0.98718113],\n       [ 0.94431669],\n       [ 0.90669322],\n       [ 0.9734726 ],\n       [ 0.99026817],\n       [ 0.9999882 ],\n       [ 0.99079728],\n       [ 0.98885113],\n       [ 0.96238601],\n       [ 0.98992598],\n       [ 0.98937267],\n       [ 0.99686396],\n       [ 0.99985647],\n       [ 0.99383968],\n       [ 0.99065757],\n       [ 1.        ],\n       [ 0.98772019],\n       [ 0.96418655],\n       [ 0.99019635],\n       [ 0.97082382],\n       [ 0.95209068],\n       [ 0.97232097],\n       [ 0.97673607],\n       [ 0.975995  ],\n       [ 0.99999988],\n       [ 0.95644808],\n       [ 0.98843932],\n       [ 0.9911828 ],\n       [ 0.99359459],\n       [ 0.9633103 ],\n       [ 0.99002624],\n       [ 0.99996805],\n       [ 0.97129536],\n       [ 0.99996245],\n       [ 0.9428007 ],\n       [ 0.96966702],\n       [ 0.97779202],\n       [ 1.        ],\n       [ 0.96018785],\n       [ 0.96390116],\n       [ 0.98937142],\n       [ 0.99910754],\n       [ 0.96367061],\n       [ 0.97586489],\n       [ 0.91565847],\n       [ 0.99992061],\n       [ 0.99991584],\n       [ 0.98837703],\n       [ 0.99079227],\n       [ 0.99120188],\n       [ 0.99079728],\n       [ 0.94099033],\n       [ 0.99079728],\n       [ 0.98780757],\n       [ 0.99319792],\n       [ 1.        ],\n       [ 1.        ],\n       [ 0.99983943],\n       [ 0.98956829],\n       [ 0.98914528],\n       [ 0.94903386],\n       [ 0.99168551],\n       [ 0.98462254],\n       [ 0.93076068],\n       [ 0.94415718],\n       [ 0.99079728],\n       [ 0.95410603],\n       [ 0.97566414],\n       [ 0.97835594],\n       [ 0.99691474],\n       [ 0.94261289],\n       [ 0.9737379 ],\n       [ 0.99127311],\n       [ 0.94663501],\n       [ 0.97681445],\n       [ 0.99999607],\n       [ 0.98980427],\n       [ 0.97222996],\n       [ 0.98625356],\n       [ 0.9999994 ],\n       [ 0.95912498],\n       [ 0.98335892],\n       [ 0.99915338],\n       [ 0.94540161],\n       [ 0.98061234],\n       [ 0.98095888],\n       [ 0.97365338],\n       [ 0.99802101],\n       [ 0.95746702],\n       [ 0.9999038 ],\n       [ 0.97730958],\n       [ 0.98370647],\n       [ 0.98620671],\n       [ 0.93247336],\n       [ 0.99999952],\n       [ 0.99079728],\n       [ 0.99948597],\n       [ 1.        ],\n       [ 0.99999428],\n       [ 0.99073762],\n       [ 0.99990118],\n       [ 0.98659098],\n       [ 0.93133903],\n       [ 0.99998999],\n       [ 0.96958983],\n       [ 0.92871374],\n       [ 0.9999789 ],\n       [ 0.99052483],\n       [ 0.97772014],\n       [ 0.99047148],\n       [ 0.97563428],\n       [ 0.9849416 ],\n       [ 0.99999976],\n       [ 0.99457836],\n       [ 0.99956495],\n       [ 0.97816533],\n       [ 0.97191626],\n       [ 0.98997986],\n       [ 0.99038786],\n       [ 0.95843375],\n       [ 0.99920624],\n       [ 0.99566013],\n       [ 0.96239638],\n       [ 0.98941821],\n       [ 0.99586487],\n       [ 0.99990928],\n       [ 0.98675472],\n       [ 0.94079733],\n       [ 0.9940064 ],\n       [ 0.93424135],\n       [ 0.99999642],\n       [ 0.93238074],\n       [ 0.98927283],\n       [ 0.99912769],\n       [ 0.99999988],\n       [ 0.98471177],\n       [ 0.98912746],\n       [ 0.99070483],\n       [ 0.99535227],\n       [ 0.99781621],\n       [ 0.94687468]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}